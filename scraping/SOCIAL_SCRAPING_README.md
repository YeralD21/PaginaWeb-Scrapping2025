# üìä Scraping de Redes Sociales con Selenium

Este documento explica c√≥mo usar los scrapers de redes sociales con **Selenium** para obtener datos **REALES** (no mock) de Facebook, Twitter y Instagram.

## üìã √çndice

- [Configuraci√≥n](#configuraci√≥n)
- [Uso](#uso)
- [Scrapers Disponibles](#scrapers-disponibles)
- [Ejemplos](#ejemplos)
- [Troubleshooting](#troubleshooting)

---

## ‚öôÔ∏è Configuraci√≥n

### 1. Instalar Selenium

```bash
pip install selenium
```

### 2. Instalar ChromeDriver

Selenium necesita **ChromeDriver** para controlar Chrome:

#### **Opci√≥n A: Autom√°tica (recomendada)**
```bash
# Selenium 4.x ya lo descarga autom√°ticamente
# No necesitas hacer nada adicional
```

#### **Opci√≥n B: Manual**
1. Descarga ChromeDriver: https://chromedriver.chromium.org/downloads
2. Extrae el ejecutable
3. Agr√©galo a PATH o col√≥calo en la misma carpeta que el script

### 3. Activar Selenium

Por defecto, los scrapers usan **datos MOCK** (r√°pidos y garantizados).

Para usar **Selenium** con scraping REAL, configura la variable de entorno:

#### **En Windows (PowerShell):**
```powershell
$env:USE_SELENIUM="true"
python main.py  # Inicia el backend
```

#### **En Linux/Mac:**
```bash
export USE_SELENIUM=true
python main.py
```

#### **En el c√≥digo:**
```python
import os
os.environ['USE_SELENIUM'] = 'true'
```

---

## üöÄ Uso

### Uso B√°sico (Modo Mock)

```python
from scraping.main_scraper import MainScraper

scraper = MainScraper()
news = scraper.scrape_social_media()
print(f"Total de noticias: {len(news)}")
```

**Ventajas del modo mock:**
- ‚úÖ R√°pido (instant√°neo)
- ‚úÖ No requiere Chrome
- ‚úÖ Funciona siempre
- ‚úÖ Datos de prueba consistentes

### Uso Avanzado (Modo Selenium)

```python
import os
os.environ['USE_SELENIUM'] = 'true'

from scraping.main_scraper import MainScraper

scraper = MainScraper()
news = scraper.scrape_social_media()
print(f"Total de noticias REALES: {len(news)}")

# Ver el contenido real
for item in news[:3]:
    print(f"\n{item['titulo']}")
    print(f"Autor: {item['autor']}")
    print(f"URL: {item['enlace']}")
```

**Ventajas del modo Selenium:**
- ‚úÖ Datos **100% reales** de redes sociales
- ‚úÖ T√≠tulos, descripciones e im√°genes reales
- ‚úÖ URLs a posts reales

**Desventajas:**
- ‚ö†Ô∏è Lento (1-2 minutos por red social)
- ‚ö†Ô∏è Puede ser bloqueado por CAPTCHAs
- ‚ö†Ô∏è Requiere Chrome instalado

---

## üì± Scrapers Disponibles

### 1. ScraperFacebookSelenium

**Fuentes:**
- El Comercio (`elcomercio.pe`)
- Diario Correo (`CorreoPeru`)
- CNN (`cnn`)
- El Popular (`elpopular.pe`)
- La Rep√∫blica (`larepublicape`)

**Datos extra√≠dos:**
- ‚úÖ T√≠tulo/post
- ‚úÖ Contenido completo
- ‚úÖ Imagen si existe
- ‚úÖ Enlace directo al post
- ‚úÖ Categor√≠a (auto-clasificada)
- ‚úÖ Fecha de publicaci√≥n

### 2. ScraperTwitterSelenium

**Fuentes:**
- `@elcomercio_peru`
- `@DiarioCorreo`
- `@rppnoticias`
- `@Peru21`
- `@cnnespanol`

**Datos extra√≠dos:**
- ‚úÖ Texto del tweet
- ‚úÖ Autor
- ‚úÖ Enlace directo
- ‚úÖ Imagen si existe
- ‚úÖ Categor√≠a
- ‚úÖ Fecha

### 3. ScraperInstagramSelenium

**‚ö†Ô∏è LIMITACIONES:**
Instagram requiere **login** para ver posts. El scraper actual:
- ‚ùå No tiene login implementado
- ‚úÖ Usa **modo mock** siempre (genera datos de prueba)

**Para implementar scraping real de Instagram**, necesitar√≠as:
1. Sistema de login (credenciales + cookies)
2. Manejo de sesiones
3. Rotaci√≥n de proxies (para evitar bloqueos)

---

## üß™ Ejemplos

### Ejemplo 1: Probar un scraper individual

```bash
# Probar Facebook (modo mock)
python scraping/scraper_facebook_selenium.py

# Probar Twitter (modo mock)
python scraping/scraper_twitter_selenium.py
```

### Ejemplo 2: Scraping desde el backend

```python
# En backend/scraping_service.py o similar

import os
os.environ['USE_SELENIUM'] = 'true'  # Activar Selenium

from scraping.main_scraper import MainScraper

scraper = MainScraper()
news = scraper.scrape_social_media()

# Guardar en BD
# ...
```

### Ejemplo 3: Scraping solo Facebook real

```python
from scraping.scraper_facebook_selenium import ScraperFacebookSelenium

scraper = ScraperFacebookSelenium()
news = scraper.get_all_news(use_real=True)

for item in news:
    print(f"{item['autor']}: {item['titulo']}")
```

---

## üîß Troubleshooting

### Error: "ChromeDriver not found"

**Soluci√≥n:**
```bash
# Verificar que Chrome est√° instalado
# Selenium 4.x descarga ChromeDriver autom√°ticamente
# Si a√∫n falla, reinstala selenium:
pip install --upgrade selenium
```

### Error: "Timeout waiting for page to load"

**Causas:**
- Red lenta
- Facebook/Twitter bloquearon la IP
- Los selectores cambiaron (la estructura de la p√°gina)

**Soluci√≥n:**
- Reducir `max_posts` a 1-2
- Aumentar timeout en WebDriverWait
- Verificar selectores actualizados

### Error: "Login required" (Instagram)

**Soluci√≥n:**
- Instagram siempre requiere login
- Usa modo mock por ahora
- Para scraping real, implementa login + cookies

### El scraping devuelve 0 noticias

**Causas:**
- Los selectores CSS cambiaron
- La p√°gina tiene CAPTCHA
- Facebook/Twitter detect√≥ bot

**Soluci√≥n:**
1. Verifica los selectores en DevTools del navegador
2. Prueba en modo no-headless (quitar `--headless`)
3. Espera unos minutos y reintenta

---

## üìä Formato de Salida

Todos los scrapers devuelven datos en este formato:

```python
{
    'titulo': 'T√≠tulo o texto principal del post',
    'contenido': 'Contenido completo del post',
    'enlace': 'https://facebook.com/page/posts/xyz',
    'imagen_url': 'https://example.com/image.jpg',
    'categoria': 'Pol√≠tica',  # Auto-clasificada
    'fecha_publicacion': datetime.now(),
    'fecha_extraccion': datetime.now().isoformat(),
    'diario': 'Facebook',  # o 'Twitter', 'Instagram'
    'diario_nombre': 'El Comercio',  # Nombre del diario
    'autor': 'El Comercio'  # o '@cuenta'
}
```

---

## üéØ Pr√≥ximos Pasos

Para mejorar los scrapers:

1. **Implementar login** para Instagram
2. **Rotaci√≥n de proxies** para evitar bloqueos
3. **Detecci√≥n de CAPTCHA** y alertas
4. **Cache de sesiones** para reutilizar logins
5. **Retry autom√°tico** con backoff exponencial
6. **Scraping incremental** (solo posts nuevos)

---

## üìù Notas Importantes

- ‚ö†Ô∏è **Respetar rate limits**: Agregar delays entre requests
- ‚ö†Ô∏è **Cambios frecuentes**: Las redes sociales cambian su HTML constantemente
- ‚ö†Ô∏è **√âtica**: Scraping solo de p√°ginas p√∫blicas
- ‚ö†Ô∏è **API oficial**: Considerar usar APIs oficiales (Facebook Graph API, Twitter API)

---

## ü§ù Contribuir

Si mejoras los scrapers:
1. Actualiza este README
2. Comenta el c√≥digo
3. Agrega logs detallados
4. Documenta nuevos selectores CSS

---

## üìö Referencias

- [Selenium Documentation](https://www.selenium.dev/documentation/)
- [WebDriverWait Best Practices](https://selenium-python.readthedocs.io/waits.html)
- [CSS Selectors](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Selectors)
- [XPath Tutorial](https://www.w3schools.com/xml/xpath_intro.asp)

